\documentclass[12pt]{article}
\usepackage[romanian]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{indentfirst}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{geometry}
\usepackage{mathtools}
\usepackage{chngcntr}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{enumitem}
\usepackage{siunitx}

\geometry{
	a4paper,
	lmargin=3cm,
	rmargin=2cm,
	tmargin=3cm,
	bmargin=2cm
}
\usetikzlibrary{arrows, shapes, automata, petri, positioning}

\theoremstyle{definition}
\newtheorem{theorem}{Teoremă}
\counterwithin*{theorem}{subsection}
\newtheorem{definition}{Definiție}
\counterwithin*{definition}{subsection}
\newtheorem{remark}{Propoziție}
\counterwithin*{remark}{subsection}
\newtheorem{lema}{Lema}
\newtheorem{algo}{Algoritmul}
\counterwithin*{algo}{subsection}


\counterwithin*{lema}{subsection}
\linespread{1.3}

\begin{document}
	\begin{titlepage}
		\begin{center}
			\vspace{1cm}
			``ALEXANDRU IOAN CUZA" UNIVERSITY OF IAȘI
			\
			\\
			\begin{large}
				\textbf{FACULTY OF COMPUTER SCIENCE}\\
			\end{large}		
			\vspace{2.5cm}
			\includegraphics{fii.png}
			\
			\\
			\vspace{1cm}
			MASTER'S THESIS
			\begin{large}
				\
				\\
				\vspace{1.5cm}
				\textbf{Human Gait Recognition}
			\end{large}
			\\
			\vspace{1.5cm}
			\textbf{proposed by}
			\\
			\vspace{1.5cm}
			\textit{\textbf{Rareș-Alexandru Stan}}
			\\
			\vspace{2cm}
			\textbf{Session:} \textit{July, 2019}
			\\
			\vspace{1.5cm}
			\textbf{Scientific Coordinator}
			\
			\\
			\
			\\
			\textbf{Lect. Dr. Ignat Anca}
			
		\end{center}
	\end{titlepage}
	\newpage
	
	\begin{titlepage}
		\begin{center}
			\textbf{``ALEXANDRU IOAN CUZA" UNIVERSITY OF IAȘI}
			\
			\\
			\textbf{FACULTY OF COMPUTER SCIENCE}\\
			\vspace{6cm}
			\
			\\
			\begin{huge}
				\textbf{Human Gait Recognition}
			\end{huge}
			\\
			\begin{large}
				\vspace{3cm}
				\textit{\textbf{Rareș-Alexandru Stan}}
				\\
				\vspace{3cm}
				\textbf{Session:} \textit{July, 2019}
				\\
			\end{large}
			\vspace{3cm}
			\textbf{Scientific Coordinator}
			\
			\\
			\textit{\textbf{Lect. Dr. Ignat Anca}	}
		\end{center}
	\end{titlepage}
	\newpage
	\tableofcontents
	\newpage
	
	\section{Introduction}
	\addcontentsline{toc}{section}{Introduction}
	\vspace{1cm}
	
	Gait is the movement pattern of the limbs during walking over a solid surface. It varies based on speed, terrain, maneuvering or efficiency of energy. This movement is unique for each human and can be used for recognizing persons from afar, without the need of their cooperation or physical contact, whereas fingerprint, iris or facial do need the physical access or their cooperation \cite{biometrics-comparison}.
	
	There are three main categories in which recognition could be classified, Machine Vision (MV), floor sensors and wearable sensors. MV is preferred because it is effective in continuous authentication and is the most non-intrusive approach.
	
	We will create a system for human gait recognition using machine Vision and Convolutional Neural Networks, that accept a series of frames with the person walking.
	
	\newpage
	
	\section{State of the Art}
	\addcontentsline{toc}{section}{State of the Art}
	\vspace{1cm}
	
	Human gait is the movement pattern of the limbs during walking. It can vary depending on the persons age, weight, how tired he is and if he is carrying extra weight. A system for recognizing persons by their walking should take all of the situations from above, to correctly identify them.
	
	There are three main approaches for identifying people by their gait, Machine Vision (MV), floor sensors and wearable sensors. Each of the three approaches have some disadvantages and advantages:
		\begin{itemize}
			\item MV:
				\begin{itemize}
					\item it is cheaper to implement, no need to install extra sensors, just some video cameras;
					\item can cover a wide area;
					\item it is affected if the people are wearing voluminous clothes;
				\end{itemize}
			\item Floor Sensors:
				\begin{itemize}
					\item are not affected by the clothes worn by the user;
					\item are more expensive to implement than MV;
					\item limited area for recognizing people;
				\end{itemize}
			\item Wearable Sensors:
				\begin{itemize}
					\item are not limited by a specific area;
					\item are not affected by the clothes worn by the user;
					\item you need to have physical access or to have their cooperation.
				\end{itemize}
		\end{itemize}
	
	In Machine Vision there are tow main approaches, model-free and model-based, where the first approach uses direct image sequences, whereas the latter needs more processing of the input sequence.
	
	\subsection{Model-Based Machine Vision}
	
	Molhema Mohualdeen and Magdi Baker \cite{gait-silhouette-nn} have proposed a model-based approach for the Gait Recognition problem using Region os Interest (ROI), Discrete Wavelet Transform (DWT), Edges, Gait Cycle and Neural Networks.
	ROI was used in the preprocessing phase to reduce data and extract the exact silhouette from each frame, by cropping. Next, in the feature extraction phase, they used DWT for multi-scale analysis, using diagonal, horizontal and vertical details of the three levels low pass and high pass filters on two dimensions DWT. Beside 3L-2D-DWT they used Edge Detection for magnitude and orientation and box technique for step and cycle length, using the with of the bounding box. Estimating the Gait Cycle was done by combining the silhouettes between the tow main phases of Gait and combining them together for each person and measuring the combination area and the width of the white shape boundary represents the step length. Classification was done using a Back Propagation Neural Network (BPNN).
	
	Munif Alotaibi and Ausif Mahmood \cite{gait-with-gei} propose a different type of preprocessing with a Convolutional Neural Network for classification. The processioning is done using the Gait Energy Image (GEI), defined as: $GEI(x, y)=1/s\sum_{t-1}^{s}F^t(x, y)$, where $s$ is the total number of frames representing the Gait Cycle and $F^t(x, y)$ is the silhouette of the subject at the time interval $t$. For determining the Gait Cycle it is used the bounding box changes method and the silhouettes are then resized to $140 * 140$ pixels. The Neural Network has 4 pairs of Convolution and Pooling layers, each with eight $5 * 5$ filters and eight sub-sampling maps with pooling factor $2$. For the activation function of the Convolutional layers it is used the Hyperbolic Tangent function. After the last Convolution and Pooling pair a Dense Layer with 124 nodes and SoftMax activation functions is used, to classify the data. For adding a new user to be recognized by the system, the old model is taken and froze the Convolutional and Pooling layers, so they are not changed during the new training period, and just the Dense Layer is modified, by adding a new node, and retrained.
	
	Hazem El-Alfy, Ikuhisa Mitsugami and Yasushi Yagi \cite{gait-with-curvature-map} build a system in which the preprocessing is done using the Gauss Map of the silhouettes and classification they use Euclidean Distance on the feature vectors between the person to be recognized and the existing database. In more details, the Gauss Maps wore done on the silhouette's surface, evaluated locally, to overcome the lack of the third dimension and made all the normal vectors point outwards the silhouette. Gauss Mapping was done on a silhouette with it's boundary extracted then smoothed using a parametric cubic spline interpolation, for it's continuity at zero, first and second order with control points being every fifth pixel of the boundary. All of the silhouettes pixels are then Distance Transformed where the distance is calculated as follows $d=max(|x_1-x_2|, |y_1-y_2|)$, where $(x_1, y_1)$ and $(x_2, y_2)$ are two distinct pixels from the image and then are computed the contour lines of the distance map. After this the image is divided in a regular grid and for each cell in computed a histogram of all the normal vectors in that contour cell. All of the cell are combined in a feature vector and it is repeated for all contours in that image. Last all the feature vectors for that image are merged into the final feature descriptor, the NDM. All of the NDMs from a full gait cycle are integrated together, using their average for the aggregate cycle descriptor. Over this aggregated feature vector the Euclidean Distance is calculated.
	
	\newpage
	
	\section{Contributions}
	\addcontentsline{toc}{section}{Contributions}
	\vspace{1cm}
	
	There are two classes for the Gait Recognition method, using Machine Vision, Model-Base and Model-Free. In the former class there are methods that preprocess the input data or extract some other information from it, which is used for classification, whereas the latter uses the raw data or with very little preprocessing as input for classification. In this theses we have tried a Model-Based approach and propose a Model-Free one for Human Gait Recognition.
	
	For training and testing data we have used the CASIA-B database \cite{casia1}\cite{casia2}\cite{casia3} as it already has the silhouettes made, which gave us the possibility to focus on the recognition methods. For new we used only the \ang{90} images, the rest will be used in a future test, and split the data in testing, nm01-nm04, for validation nm-05 and for testing nm-06.
	
	We have tried two different approaches, one Model-Based, in which the input images were cropped, smoothed and then a surface curvature metric was extracted from the silhouette and then classified using a Convolutional Neural Network, and one Model-Free, where the input images were cropped and then feed to a Convolutional Neural Network for classification
	
	Through surface curvature metric we refer to a function that can map the shape, position and altitude, from an image with three dimensional objects, to a numerical value, for each pixel in the original image.
	
	Smoothing refers to the process of removing noise or fine-scale structures from images, resulting in a less jagged edges and sharp curves/transitions.
	
	\newpage
	
	\section{Approach}
	\addcontentsline{toc}{section}{Approach}
	\vspace{1cm}
	
	In the first part ot this chapter we will present the architecture and methods used for the Model-Based approach and after that the Model-Free system. At the start of each description there will be defined what the method uses for preprocessing and classification.
	
	\subsection{Model-Based Approach}
	
	The shape index is a measure of local curvature, derived from the eigen values of the Hessian, defined by Koenderink and van Doorn \cite{shape-index}. It can be used to find structures based on their apparent local shape. It maps to values in the range $[-1, 1]$, representing different shape types. It is defined as follows:
	
	\begin{equation*}
	s=\frac{2}{\pi}*\arctan{\frac{k_2+k_1}{k_2-k_1}} \;\;\;\;  (k_1 \geq k_2)
	\end{equation*}
	
	Here $(k_1, k_2)$ are polar coordinates described by $k_{1,2}^2-2H_{k_{1,2}}+K=0$, where $H$ is the mean curvature, measuring the spread of normals for the points of infinitesimal arcs, divided by the arch length and averaged over all surfaces, and $K$ is the Gaussian curvature, specifying the spread of normals.
	
	Neural Networks are a collection of connected nodes, name neurons, that for a node $j$, at the time interval $t$, with input  $p_j(t)$, consist of:
	\begin{itemize}
		\item an activation $a_j(t)$,
		\item a threshold $\theta_j$,
		\item an activation function $f$ that computes the new activation at time $t+1$ from $a_j(t), \theta_j$ and the input $p_j(t)$, resulting $a_j(t+1)=f(a_j(t), p_j(t), \theta_j)$,
		\item and an output $o_j(t)=f_{out}(a_j(t))$
	\end{itemize}
	and with a propagation function, that computes the input $p_j(t)$, for node $j$, from $o_i(t)$ of predecessor neurons and has the form $p_j(t)=\sum_io_i(t)*w_{ij} + w_{0j}$, where $w_{0j}$ is a bias.
	
	Learning in Neural Networks is done by first doing a feed forward, computing the output of the network, for the input $x, x \in \mathbb{R}^n$, where $n$ is the size of the input vector, then computing the error of the entire network for the known input and propagating the error and updating the weights for each layer in the network like so
	\begin{equation*}
		w_{ij}(t+1)=w_{ij}(t)-\eta\frac{\partial C}{\partial w_{ij}}+ \xi(t)
	\end{equation*}
	
	where $\eta$ is the learning rate, $C$ is the cost function, and $\xi(t)$ a stochastic term. The cost function depends on the learning type and the activation function, usually in supervised learning the cost function is Cross Entropy. Backpropagation is done for each training sample for the desired number of epochs.
	
	Convolutional Neural Networks beside the classic dense layers they have a convolution and pooling layer and they are primarily used for image and video related learning.
	Convolutional layers have multiple filters of fixed dimensions, randomly initialized in a uniform distribution. The $a*b$ filter is applied over the input $x$, using the dot product between the filter and sub-matrix of $x$,  with a stride $s$, and the output is added with the bias term and then the activation function is applied, this happens for all the defined filters for a specific convolutional layer independently. Pooling layers reduce the size of the input by a specified factor, using a specific function, max, average or min, so that the following filters theoretically look at bigger feature of the input. Dense layers are usually used just for output labeling or additional classifying.
	
	\newpage
	
	\section{Conclusions}
	\addcontentsline{toc}{section}{Conclusions}
	\vspace{1cm}
	
	\newpage
	
	\section{Bibliography}
	\addcontentsline{toc}{section}{Bibliography}
	\bibliography{bibliografie}
	\bibliographystyle{ieeetr}
	
\end{document}